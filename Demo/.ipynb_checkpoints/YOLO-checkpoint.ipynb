{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, RTDETR\n",
    "\n",
    "model = YOLO(\"../runs/segment/yolov8x-seg.pt_1280/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = glob.glob(\"../runs/*/*/weights/best.pt\")\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32501MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/azakeri/Mushroom/m18k/M18K/Data/test/labels.cache... 42 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<?, ?it/s]\n",
      "/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         42       1705      0.903      0.912      0.961      0.871      0.899      0.905      0.955        0.8\n",
      "                    BB         42       1252      0.834      0.906      0.943       0.81      0.827      0.893      0.932      0.685\n",
      "                    WB         42        453      0.972      0.918      0.978      0.932      0.972      0.917      0.977      0.916\n",
      "Speed: 7.6ms preprocess, 1.9ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val4\u001b[0m\n",
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32501MiB)\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71722582 parameters, 0 gradients, 343.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/azakeri/Mushroom/m18k/M18K/Data/test/labels.cache... 42 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<?, ?it/s]\n",
      "/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         42       1705      0.907      0.914      0.971       0.91      0.907      0.914      0.968      0.826\n",
      "                    BB         42       1252      0.872      0.879      0.955      0.877      0.872      0.879      0.954      0.731\n",
      "                    WB         42        453      0.941      0.949      0.987      0.943      0.941      0.949      0.983       0.92\n",
      "Speed: 10.1ms preprocess, 49.4ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val5\u001b[0m\n",
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32501MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27223542 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/azakeri/Mushroom/m18k/M18K/Data/test/labels.cache... 42 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<?, ?it/s]\n",
      "/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         42       1705      0.897      0.927      0.968      0.901      0.915      0.903      0.964      0.818\n",
      "                    BB         42       1252      0.841      0.902       0.95      0.859      0.869      0.871      0.946       0.72\n",
      "                    WB         42        453      0.953      0.951      0.985      0.942      0.962      0.936      0.983      0.915\n",
      "Speed: 8.6ms preprocess, 47.6ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val6\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda972b1120>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32501MiB)\n",
      "YOLOv8l-seg summary (fused): 295 layers, 45913430 parameters, 0 gradients, 220.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/azakeri/Mushroom/m18k/M18K/Data/test/labels.cache... 42 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<?, ?it/s]\n",
      "/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         42       1705      0.903       0.92      0.968      0.915      0.903       0.92      0.968      0.899\n",
      "                    BB         42       1252      0.856      0.891      0.951      0.882      0.856      0.891      0.951      0.854\n",
      "                    WB         42        453       0.95      0.949      0.985      0.947       0.95      0.949      0.984      0.944\n",
      "Speed: 30.3ms preprocess, 66.0ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/val7\u001b[0m\n",
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM3-32GB, 32501MiB)\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71722582 parameters, 0 gradients, 343.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/azakeri/Mushroom/m18k/M18K/Data/test/labels.cache... 42 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<?, ?it/s]\n",
      "/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:09<?, ?it/s]\n",
      "Exception in thread Thread-53 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/azakeri/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/azakeri/miniconda3/envs/hr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(m)\n\u001b[1;32m     11\u001b[0m model_data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:model_name,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mint\u001b[39m(image_size)}\n\u001b[0;32m---> 12\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m new_row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mresults_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_data}\n\u001b[1;32m     14\u001b[0m rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [new_row]\n",
      "File \u001b[0;32m~/miniconda3/envs/hr/lib/python3.10/site-packages/ultralytics/engine/model.py:514\u001b[0m, in \u001b[0;36mModel.val\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    513\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 514\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/miniconda3/envs/hr/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hr/lib/python3.10/site-packages/ultralytics/engine/validator.py:192\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;129;01mand\u001b[39;00m batch_i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_val_samples(batch, batch_i)\n\u001b[0;32m--> 192\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_val_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_stats()\n",
      "File \u001b[0;32m~/miniconda3/envs/hr/lib/python3.10/site-packages/ultralytics/models/yolo/segment/val.py:208\u001b[0m, in \u001b[0;36mSegmentationValidator.plot_predictions\u001b[0;34m(self, batch, preds, ni)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_predictions\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, preds, ni):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plots batch predictions with masks and bounding boxes.\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     plot_images(\n\u001b[1;32m    207\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[43moutput_to_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# not set to self.args.max_det due to slow plotting speed\u001b[39;00m\n\u001b[1;32m    209\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_masks) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_masks,\n\u001b[1;32m    210\u001b[0m         paths\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mim_file\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    211\u001b[0m         fname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_batch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mni\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pred.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    212\u001b[0m         names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,\n\u001b[1;32m    213\u001b[0m         on_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_plot,\n\u001b[1;32m    214\u001b[0m     )  \u001b[38;5;66;03m# pred\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_masks\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/miniconda3/envs/hr/lib/python3.10/site-packages/ultralytics/utils/plotting.py:999\u001b[0m, in \u001b[0;36moutput_to_target\u001b[0;34m(output, max_det)\u001b[0m\n\u001b[1;32m    997\u001b[0m targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output):\n\u001b[0;32m--> 999\u001b[0m     box, conf, \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mo\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1000\u001b[0m     j \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((conf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m), i)\n\u001b[1;32m   1001\u001b[0m     targets\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mcat((j, \u001b[38;5;28mcls\u001b[39m, ops\u001b[38;5;241m.\u001b[39mxyxy2xywh(box), conf), \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "models = glob.glob(\"../runs/*/*/weights/best.pt\")\n",
    "print(len(models))\n",
    "for m in models:\n",
    "    \n",
    "    model_name, image_size = m.split(\"/\")[-3].split(\"_\")\n",
    "    model_name = model_name.replace(\".pt\",\"\")\n",
    "    model = YOLO(m)\n",
    "    model_data={\"model_name\":model_name,\"image_size\":int(image_size)}\n",
    "    metrics = model.val(imgsz=int(image_size),half=False,plots=True,batch=1)\n",
    "    new_row = {**metrics.results_dict, **model_data}\n",
    "    rows += [new_row]\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"yolo_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/precision(B)': 0.9072022282427918,\n",
       " 'metrics/recall(B)': 0.9189290359448439,\n",
       " 'metrics/mAP50(B)': 0.9657822792314439,\n",
       " 'metrics/mAP50-95(B)': 0.9179845666688085,\n",
       " 'metrics/precision(M)': 0.9065127800585115,\n",
       " 'metrics/recall(M)': 0.9188491916232628,\n",
       " 'metrics/mAP50(M)': 0.9655683473543866,\n",
       " 'metrics/mAP50-95(M)': 0.89676063890702,\n",
       " 'fitness': 1.8264057476768287}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0,\"..\") \n",
    "\n",
    "from M18K.Data.Dataset import M18KDataset\n",
    "\n",
    "ds = M18KDataset(root=\"train\",transforms=None,train=True, depth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-seg')\n",
    "results = model.train(data=ds, epochs=100, imgsz=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.yolo.detect import DetectionTrainer\n",
    "from ultralytics.utils import DEFAULT_CFG\n",
    "\n",
    "\n",
    "class CustomTrainer(DetectionTrainer):\n",
    "    def __init__(self, overrides=None, _callbacks=None):\n",
    "        super().__init__(DEFAULT_CFG, {\"task\":\"detect\",\"data\":\"/home/azakeri/Mushroom/YOLO/datasets/data.yaml\"}, _callbacks)\n",
    "        self.args.task = \"detect\"\n",
    "        self.args.data = \"/home/azakeri/Mushroom/YOLO/datasets/data.yaml\"\n",
    "        self.data = \"/home/azakeri/Mushroom/YOLO/datasets/data.yaml\"\n",
    "\n",
    "    # def build_dataset():\n",
    "    #     return ds\n",
    "\n",
    "trainer = CustomTrainer()\n",
    "da = trainer.get_dataset({\"train\":\"/home/azakeri/Mushroom/YOLO/datasets/data.yaml\"})\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "for mode in [\"train\",\"valid\",\"test\"]:\n",
    "    images = glob.glob(f\"../M18K/Data/{mode}/*.jpg\")\n",
    "    for i in images:\n",
    "        filename = i.split(\"/\")[-1][:-4]\n",
    "        src = f\"/home/azakeri/Mushroom/YOLO/datasets/{mode}/labels/{filename}.txt\"\n",
    "        if os.path.exists(src):\n",
    "            \n",
    "            shutil.copyfile(src,f\"/home/azakeri/Mushroom/m18k/M18K/Data/{mode}/{filename}.txt\")\n",
    "        else:\n",
    "            print(src)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define your main directories\n",
    "directories = ['/home/azakeri/Mushroom/m18k/M18K/Data/train', '/home/azakeri/Mushroom/m18k/M18K/Data/valid', '/home/azakeri/Mushroom/m18k/M18K/Data/test']\n",
    "\n",
    "# Define the extensions for each file type\n",
    "image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "label_extensions = ['.txt']\n",
    "depth_extensions = ['.npy']\n",
    "\n",
    "for dir in directories:\n",
    "    # Create paths for the images, labels, and depth subdirectories\n",
    "    images_dir = os.path.join(dir, 'images')\n",
    "    labels_dir = os.path.join(dir, 'labels')\n",
    "    depth_dir = os.path.join(dir, 'depth')\n",
    "    \n",
    "    # Create the subdirectories if they don't exist\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    os.makedirs(depth_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through each file in the main directory\n",
    "    for filename in os.listdir(dir):\n",
    "        file_path = os.path.join(dir, filename)\n",
    "        \n",
    "        # Move images\n",
    "        if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "            shutil.move(file_path, os.path.join(images_dir, filename))\n",
    "        \n",
    "        # Move labels\n",
    "        elif any(filename.lower().endswith(ext) for ext in label_extensions):\n",
    "            shutil.move(file_path, os.path.join(labels_dir, filename))\n",
    "        \n",
    "        # Move depth files\n",
    "        elif any(filename.lower().endswith(ext) for ext in depth_extensions):\n",
    "            shutil.move(file_path, os.path.join(depth_dir, filename))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
