{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "\n",
    "class M18KDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.annotations = COCO(os.path.join(root, \"_annotations.coco.json\"))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        image_object = self.annotations.imgs[idx]\n",
    "        img_path = image_object[\"file_name\"]\n",
    "        #mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img = read_image(os.path.join(self.root,img_path))\n",
    "        masks = self.annotations.loadAnns(self.annotations.getAnnIds([image_object[\"id\"]]))\n",
    "        \n",
    "        num_objs = len(masks)\n",
    "\n",
    "        # tensor of shape [#objects,h,w] of binary masks\n",
    "        binary_masks = torch.tensor(np.dstack([annotations.annToMask(mask) for mask in masks]),dtype=torch.uint8).permute([2,0,1])\n",
    "        \n",
    "        # get bounding box coordinates for each mask\n",
    "        boxes = masks_to_boxes(binary_masks)\n",
    "\n",
    "        # there is only one class\n",
    "        labels = torch.tensor([mask[\"category_id\"] for mask in masks],dtype=torch.int64)\n",
    "\n",
    "        image_id = idx\n",
    "        area = torch.tensor([mask[\"area\"] for mask in masks],dtype=torch.float32)\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.tensor([mask[\"iscrowd\"] for mask in masks],dtype=torch.int64)\n",
    "\n",
    "        # Wrap sample and targets into torchvision tv_tensors:\n",
    "        img = tv_tensors.Image(img)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
    "        target[\"masks\"] = tv_tensors.Mask(binary_masks)\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            print(type(target))\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations.imgs)\n",
    "\n",
    "ds = M18KDataset(\"M18K/Dataset/train\",None)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a9a09b7e36868",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc2f50fbfd53e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = COCO(os.path.join(\"M18K/Dataset/train\", \"_annotations.coco.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f95d5386caf15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a351ce53300eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = read_image(os.path.join(\"M18K/Dataset/train\",annotations.imgs[0][\"file_name\"]))\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ddee0d28eea001",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "masks = annotations.loadAnns(annotations.getAnnIds([annotations.imgs[0][\"id\"]]))\n",
    "binary_masks = torch.tensor(np.dstack([annotations.annToMask(mask) for mask in masks]),dtype=torch.uint8).permute([2,0,1])\n",
    "binary_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef4ed51f66782de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:21:28.336641Z",
     "start_time": "2024-01-02T22:21:25.582634Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from M18K.Data.Dataset import M18KDataset\n",
    "from M18K.Data.DataModule import M18KDataModule\n",
    "from M18K.Models.TorchVision import MaskRCNN_ResNet50\n",
    "from lightning import LightningModule, Trainer\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "import argparse\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5fb0100ac29c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:33:27.600503Z",
     "start_time": "2024-01-02T22:33:26.682685Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from M18K.Data.Dataset import M18KDataset\n",
    "from M18K.Data.DataModule import M18KDataModule\n",
    "from M18K.Models.TorchVision import MaskRCNN_ResNet50\n",
    "from lightning import LightningModule, Trainer\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "import argparse\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "def main(model_name=\"resnet_18\"):\n",
    "    # Instantiate the data module\n",
    "    t = transforms.ToTensor()\n",
    "    # if model_name == \"swin_v2_b\":\n",
    "    #     t = transforms.Compose([transforms.ToTensor(),transforms.Grayscale()])\n",
    "    dm = M18KDataModule(batch_size=2)\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = MaskRCNN_ResNet50()\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=100,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=f\"runs/{model_name}/\",\n",
    "        filename= model_name+\"-{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}\",\n",
    "    )\n",
    "\n",
    "    #early_stop_callback = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00, patience=50, verbose=False, mode=\"max\")\n",
    "\n",
    "    # Initialize a trainer\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(save_dir=f\"runs/{model_name}/\")\n",
    "    trainer = Trainer(max_epochs=100,devices=1,log_every_n_steps=1,logger=tb_logger,callbacks=[checkpoint_callback])\n",
    "\n",
    "    # Train the model âš¡\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # parser = argparse.ArgumentParser(description='A simple script with command-line arguments.')\n",
    "    # parser.add_argument('model', type=str, help='model name')\n",
    "    # args = parser.parse_args()\n",
    "    # model = args.model\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e36235369b81a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:21:15.460283Z",
     "start_time": "2024-01-02T22:21:08.053255Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649a351e4f55c219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:21:30.102094Z",
     "start_time": "2024-01-02T22:21:28.626692Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.44s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ds = M18KDataset(root=\"M18K/Data/train\",transforms=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7181b86fde01cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:24:28.976270Z",
     "start_time": "2024-01-02T22:24:27.385455Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch=[ds[0],ds[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90066eef5f18fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:24:30.581003Z",
     "start_time": "2024-01-02T22:24:30.550710Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6e1f53bcb243d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:24:48.039715Z",
     "start_time": "2024-01-02T22:24:48.015404Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images,targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7dd5023d1a3ada0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:24:51.440458Z",
     "start_time": "2024-01-02T22:24:51.418280Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2118, 0.2118, 0.2078,  ..., 0.4941, 0.4706, 0.5412],\n",
       "          [0.1961, 0.2000, 0.2000,  ..., 0.5373, 0.5098, 0.5490],\n",
       "          [0.2000, 0.1961, 0.1882,  ..., 0.5451, 0.5098, 0.5216],\n",
       "          ...,\n",
       "          [0.2353, 0.2510, 0.2353,  ..., 0.5255, 0.3725, 0.3333],\n",
       "          [0.2314, 0.2314, 0.2235,  ..., 0.5098, 0.3608, 0.3216],\n",
       "          [0.2314, 0.2196, 0.2118,  ..., 0.3255, 0.2863, 0.3608]],\n",
       " \n",
       "         [[0.2353, 0.2353, 0.2196,  ..., 0.5490, 0.5529, 0.6275],\n",
       "          [0.2196, 0.2235, 0.2118,  ..., 0.5922, 0.5804, 0.6353],\n",
       "          [0.2196, 0.2157, 0.2000,  ..., 0.5961, 0.5765, 0.6039],\n",
       "          ...,\n",
       "          [0.2118, 0.2392, 0.2157,  ..., 0.4667, 0.3020, 0.2510],\n",
       "          [0.2157, 0.2275, 0.2118,  ..., 0.4471, 0.2863, 0.2392],\n",
       "          [0.2275, 0.2157, 0.2078,  ..., 0.2627, 0.2118, 0.2784]],\n",
       " \n",
       "         [[0.2157, 0.2157, 0.2118,  ..., 0.5451, 0.5451, 0.6196],\n",
       "          [0.2000, 0.2039, 0.2039,  ..., 0.5882, 0.5765, 0.6275],\n",
       "          [0.2118, 0.2078, 0.1922,  ..., 0.5882, 0.5647, 0.5922],\n",
       "          ...,\n",
       "          [0.2549, 0.2745, 0.2510,  ..., 0.4588, 0.3059, 0.2588],\n",
       "          [0.2588, 0.2627, 0.2471,  ..., 0.4510, 0.2980, 0.2510],\n",
       "          [0.2667, 0.2510, 0.2431,  ..., 0.2667, 0.2235, 0.2902]]]),\n",
       " tensor([[[0.4314, 0.4275, 0.4235,  ..., 0.1529, 0.1961, 0.2196],\n",
       "          [0.4275, 0.4235, 0.4196,  ..., 0.2118, 0.2431, 0.2627],\n",
       "          [0.4157, 0.4157, 0.4118,  ..., 0.2784, 0.2667, 0.2667],\n",
       "          ...,\n",
       "          [0.3412, 0.3412, 0.3373,  ..., 0.3137, 0.3098, 0.3059],\n",
       "          [0.3490, 0.3529, 0.3451,  ..., 0.3137, 0.3098, 0.3059],\n",
       "          [0.3490, 0.3529, 0.3490,  ..., 0.3137, 0.3098, 0.3098]],\n",
       " \n",
       "         [[0.4078, 0.4039, 0.4000,  ..., 0.1608, 0.2118, 0.2471],\n",
       "          [0.4039, 0.4000, 0.3961,  ..., 0.2196, 0.2588, 0.2902],\n",
       "          [0.3922, 0.3922, 0.3882,  ..., 0.2863, 0.2824, 0.2824],\n",
       "          ...,\n",
       "          [0.2980, 0.2980, 0.2902,  ..., 0.2627, 0.2588, 0.2549],\n",
       "          [0.3020, 0.3020, 0.2980,  ..., 0.2627, 0.2588, 0.2549],\n",
       "          [0.3020, 0.3059, 0.3020,  ..., 0.2627, 0.2588, 0.2588]],\n",
       " \n",
       "         [[0.3569, 0.3529, 0.3490,  ..., 0.1137, 0.1647, 0.1961],\n",
       "          [0.3529, 0.3490, 0.3451,  ..., 0.1725, 0.2118, 0.2392],\n",
       "          [0.3412, 0.3412, 0.3373,  ..., 0.2392, 0.2353, 0.2353],\n",
       "          ...,\n",
       "          [0.1922, 0.1922, 0.1961,  ..., 0.1765, 0.1725, 0.1686],\n",
       "          [0.1922, 0.2000, 0.2039,  ..., 0.1765, 0.1725, 0.1686],\n",
       "          [0.1922, 0.1961, 0.2078,  ..., 0.1765, 0.1725, 0.1725]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ce778401ab7967f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:25:40.502054Z",
     "start_time": "2024-01-02T22:25:22.808419Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(3.2122, grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(0.6233, grad_fn=<DivBackward0>),\n",
       " 'loss_mask': tensor(0.3126, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_objectness': tensor(2.0911, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0.0579, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead59d089b05fa76",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
